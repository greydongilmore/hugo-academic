{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised learning\n",
    "\n",
    "Machine learning techniques come in two general flavors: **supervised learning** and **unsupervised learning**. Learning is supervised whenever we know the true values that our model is trying to predict, and hence, are in a position to \"supervise\" the learning process by quantifying prediction accuracy and making iterative adjustments.\n",
    "\n",
    "Some examples of supervised learning problems:\n",
    "\n",
    "* Determining whether or not incoming email is spam\n",
    "* Predicting a person's age from personality scores\n",
    "* Diagnosing schizophrenia based on genetic markers\n",
    "\n",
    "Within the class of supervised learning problems, we can draw a further distinction between **classification** problems and **regression** problems. In both cases, the goal is to develop a predictive model that recovers the true labels as accurately as possible. The difference between the two lies in the nature of the labels: in classification, the labels are discrete; in regression, they're continuous.\n",
    "\n",
    "# Classification\n",
    "\n",
    "Now let's look at classification. In this case, the target labels we're trying to predict are discrete (or categorical). For example, building a model that takes a structural brain image as input and outputs a prediction about whether the brain belongs to a dog or a cat is a classification problem, because the output is discrete: each brain belongs to one of the two classes (or categories), and no brain ever takes on an an intermediate value (though our classifiers can certainly make a graded or probabilistic prediction about which class a brain belongs to).\n",
    "\n",
    "In practice, we can often turn regression problems into classification problems by discretizing the data in some way. To make the point really clear, let's stick with our personality dataset. Notice that instead of trying to predict continuous age from personality (a regression problem), we *could* in principle bin people into groups based on their age, and then try to develop a model that can correctly *classify* people as \"young\" or \"old\" based on their self-reported personality scores. Almost any regression problem can be turned into a classification problem in this way (the converse is not generally true).\n",
    "\n",
    "I hasten to emphasize that discretizing continuous data for classification purposes is generally *not* a good thing to do (even though it's quite common in many social and biomedical sciences). But we'll allow ourselves the liberty in this particular case, because one thing the act of discretization does make clear is the close relationship between the two kinds of problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised learning\n",
    "\n",
    "Learning is unsupervised when there's no ground truth or right answer, and the goal is just to learn some useful structure from the data. The learning algorithm receives no direct guidance about how well it's performing.\n",
    "\n",
    "For example, suppose someone hands us the following data, with no further explanation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn has some handy utilities for generating structure data\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(random_state=1, cluster_std=1)\n",
    "plt.scatter(*X.T);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be natural to think that these data are generated from three distinct *clusters*. But since the data are unlabeled, we don't know for a fact that this assignment is correct; we're inferring the grouping in an unsupervised way, based on whatever principle are built into our estimation method (e.g., our visual system's tendency to group objects together based on proximity). The lack of access to the ground truth—and often, it's not even clear that there *is* any ground truth—underscores the difficulty of the unsupervised learning challenge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
